import numpy as np
import json
import os
from algorithm import TicTacToeQLearning
from algorithm import TicTacToeGame

def load_json_data(file_path):
    if not os.path.exists(file_path):
        print(f"Warning: File '{file_path}' not found. Returning empty dictionary.")
        return {}

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"Data successfully loaded from '{file_path}'.")
        return data
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{file_path}'. File might be corrupted or empty.")
        return {}
    except Exception as e:
        print(f"An unexpected error occurred while loading '{file_path}': {e}")
        return {}

def update_json_file(file_path, data):
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"Data successfully updated to '{file_path}'.")
        return True
    except Exception as e:
        print(f"Error: Could not update JSON file '{file_path}': {e}")
        return False

def rule_based_ai_move(board):
    """AI ‡∏ù‡∏±‡πà‡∏á O ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÅ‡∏ö‡∏ö if-else"""
    def check_win(b, p):
        for i in range(3):
            if np.sum(b[i, :] == p) == 2 and 0 in b[i, :]:
                return i, list(b[i, :]).index(0)
            if np.sum(b[:, i] == p) == 2 and 0 in b[:, i]:
                return list(b[:, i]).index(0), i
        if np.sum([b[i, i] == p for i in range(3)]) == 2:
            for i in range(3):
                if b[i, i] == 0:
                    return i, i
        if np.sum([b[i, 2 - i] == p for i in range(3)]) == 2:
            for i in range(3):
                if b[i, 2 - i] == 0:
                    return i, 2 - i
        return None

    def is_fork_move(b, p):
        """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ù‡πà‡∏≤‡∏¢ p ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏à‡∏∞ fork ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        count = 0
        for i in range(3):
            for j in range(3):
                if b[i, j] == 0:
                    b[i, j] = p
                    if check_win(b, p):
                        count += 1
                    b[i, j] = 0
        return count >= 2

    # 1. ‡∏ä‡∏ô‡∏∞‡πÑ‡∏î‡πâ‡πÉ‡∏´‡πâ‡∏ä‡∏ô‡∏∞
    pos = check_win(board, -1)
    if pos: return pos[0] * 3 + pos[1] + 1

    # 2. ‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ X ‡∏ä‡∏ô‡∏∞
    pos = check_win(board, 1)
    if pos: return pos[0] * 3 + pos[1] + 1

    # 3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
    if board[1, 1] == 0: return 5

    # 4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏∏‡∏°‡∏ß‡πà‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô
    for i, j in [(0, 0), (0, 2), (2, 0), (2, 2)]:
        if board[i, j] == 0:
            return i * 3 + j + 1

    # 5. ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Fork ‡∏Ç‡∏≠‡∏á X
    for i in range(3):
        for j in range(3):
            if board[i, j] == 0:
                board[i, j] = 1
                if is_fork_move(board, 1):
                    board[i, j] = 0
                    return i * 3 + j + 1
                board[i, j] = 0

    # 6. ‡∏™‡∏£‡πâ‡∏≤‡∏á Fork ‡πÉ‡∏´‡πâ O
    for i in range(3):
        for j in range(3):
            if board[i, j] == 0:
                board[i, j] = -1
                if is_fork_move(board, -1):
                    board[i, j] = 0
                    return i * 3 + j + 1
                board[i, j] = 0

    # 7. ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å
    for i in range(3):
        for j in range(3):
            if board[i, j] == 0:
                return i * 3 + j + 1

    return None

def train_ai(ai, game_data, episodes=1000):
    """‡πÄ‡∏ó‡∏£‡∏ô AI ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á"""
    print(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô AI {episodes} ‡∏ï‡∏≤...")

    wins = {'ai': 0, 'opponent': 0, 'draw': 0}

    for episode in range(episodes):
        game = TicTacToeGame()
        game_history = []

        while True:
            current_state = game.board.copy()

            if game.current_player == 1:
                action = ai.choose_action(current_state, training=True)
            else:
                a = rule_based_ai_move(current_state)
                if a is not None:
                    action = a
                else:
                    action = ai.choose_action(current_state, training=True)

            if action is None:
                break

            game_history.append([
                ai.state_to_string(current_state),
                action - 1,
                game.current_player
            ])

            game.make_move(action, game.current_player)

            winner = game.check_winner()
            if winner is not None:
                if winner == 1:
                    wins['ai'] += 1
                elif winner == -1:
                    wins['opponent'] += 1
                else:
                    wins['draw'] += 1

                for i, (state, act, player) in enumerate(game_history):
                    if winner == 1:
                        reward = 2 if player == 1 else -2
                    elif winner == -1:
                        reward = -2 if player == 1 else 2
                    else:
                        reward = -1 if player == 1 else 1

                    if i < len(game_history) - 1:
                        next_state = game_history[i + 1][0]
                    else:
                        next_state = ai.state_to_string(game.board)

                    if player == 1:
                        ai.update_q_value(state, act, reward, next_state)

                break

            game.current_player *= -1

        if (episode + 1) % 100 == 0:
            print(f"Episode {episode + 1}/{episodes} - "
                  f"AI ‡∏ä‡∏ô‡∏∞: {wins['ai']}, ‡πÅ‡∏û‡πâ: {wins['opponent']}, ‡πÄ‡∏™‡∏°‡∏≠: {wins['draw']}")

    print(f"\n‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    print(f"‡∏ú‡∏•‡∏£‡∏ß‡∏° - AI ‡∏ä‡∏ô‡∏∞: {wins['ai']}, ‡πÅ‡∏û‡πâ: {wins['opponent']}, ‡πÄ‡∏™‡∏°‡∏≠: {wins['draw']}")
    game_data['win'] += wins['ai']
    game_data['lose'] += wins['opponent']
    game_data['draw'] += wins['draw']

    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ
    stats = ai.get_learning_stats()
    print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:")
    print(f"   ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ: {stats['total_states']}")
    print(f"   ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_actions']}")
    print(f"   ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å: {stats['positive_q']}")
    print(f"   ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö: {stats['negative_q']}")

    ai.epsilon = 0.05
    ai.save_q_table()


def play_with_human(ai, game_data):
    """‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏à‡∏£‡∏¥‡∏á"""
    print("\n=== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö AI ===")
    print("‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô O (‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô), AI ‡πÄ‡∏õ‡πá‡∏ô X (‡∏™‡∏µ‡πÅ‡∏î‡∏á)")
    print("‡πÉ‡∏™‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 1-9")

    show_ai_thinking = True
    show_learning = True

    game_count = 0
    wins = {'human': 0, 'ai': 0, 'draw': 0}

    while True:
        game = TicTacToeGame()
        game_history = []
        game_count += 1

        print(f"\n{'=' * 50}")
        print(f"‡πÄ‡∏Å‡∏°‡∏ó‡∏µ‡πà {game_count}")
        print('=' * 50)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        if game_count == 1:
            stats = ai.get_learning_stats()
            print(f"üìö AI ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å {stats['total_states']} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß")

        game.print_board()

        while True:
            current_state = game.board.copy()

            if game.current_player == 1:  # AI ‡πÄ‡∏•‡πà‡∏ô
                action = ai.choose_action(current_state, training=False, show_thinking=show_ai_thinking)

                if action is None:
                    break

                game_history.append([
                    ai.state_to_string(current_state),
                    action - 1,
                    game.current_player
                ])

                game.make_move(action, game.current_player)
                print(f"\nü§ñ AI ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á {action}")

            else:  # Human ‡πÄ‡∏•‡πà‡∏ô
                game.print_board()
                try:
                    human_input = input(
                        "\n‡πÉ‡∏™‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (1-9), 't' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î AI, 'l' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ, ‡∏´‡∏£‡∏∑‡∏≠ 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å: ")

                    if human_input.lower() == 'q':
                        return
                    elif human_input.lower() == 't':
                        show_ai_thinking = not show_ai_thinking
                        status = "‡πÄ‡∏õ‡∏¥‡∏î" if show_ai_thinking else "‡∏õ‡∏¥‡∏î"
                        print(f"‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á AI: {status}")
                        continue
                    elif human_input.lower() == 'l':
                        show_learning = not show_learning
                        status = "‡πÄ‡∏õ‡∏¥‡∏î" if show_learning else "‡∏õ‡∏¥‡∏î"
                        print(f"‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ: {status}")
                        continue

                    action = int(human_input)
                    if action < 1 or action > 9:
                        print("‚ùå ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 1-9")
                        continue

                    if not game.make_move(action, game.current_player):
                        print("‚ùå ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß!")
                        continue

                    game_history.append([
                        ai.state_to_string(current_state),
                        action - 1,
                        game.current_player
                    ])

                except ValueError:
                    print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç!")
                    continue

            winner = game.check_winner()
            if winner is not None:
                print("\n" + "=" * 50)
                game.print_board()

                if winner == 1:
                    print("ü§ñ AI ‡∏ä‡∏ô‡∏∞!")
                    wins['ai'] += 1
                    game_data["win"] += 1
                elif winner == -1:
                    print("üéâ ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏ô‡∏∞!")
                    wins['human'] += 1
                    game_data["lose"] += 1
                else:
                    print("ü§ù ‡πÄ‡∏™‡∏°‡∏≠!")
                    wins['draw'] += 1
                    game_data["draw"] += 1

                # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á AI
                if show_learning:
                    print(f"\nüß† AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏°‡∏ô‡∏µ‡πâ...")

                # AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô
                learned_something = False
                for i, (state, act, player) in enumerate(game_history):
                    if player == 1:  # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏Ç‡∏≠‡∏á AI
                        old_q = ai.q_table[state][act]

                        if winner == 1:
                            reward = 1
                        elif winner == -1:
                            reward = -1
                        else:
                            reward = 0

                        if i < len(game_history) - 1:
                            next_state = game_history[i + 1][0]
                        else:
                            next_state = ai.state_to_string(game.board)

                        ai.update_q_value(state, act, reward, next_state, show_learning=show_learning)

                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                        new_q = ai.q_table[state][act]
                        if abs(new_q - old_q) > 0.001:
                            learned_something = True

                print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ - ‡∏Ñ‡∏∏‡∏ì: {wins['human']}, AI: {wins['ai']}, ‡πÄ‡∏™‡∏°‡∏≠: {wins['draw']}")
                game_data['all_game'] = game_data['win'] + game_data['lose'] + game_data['draw']
                print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ AI - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô: {game_data['all_game']}, ‡∏ä‡∏ô‡∏∞: {game_data['win']}, ‡πÅ‡∏û‡πâ: {game_data['lose']}, ‡πÄ‡∏™‡∏°‡∏≠: {game_data['draw']}")

                # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á AI
                if learned_something:
                    if winner == -1:  # ‡∏´‡∏≤‡∏Å AI ‡πÅ‡∏û‡πâ
                        print("üß† AI ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß (Q-values ‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î)")
                    elif winner == 1:  # ‡∏´‡∏≤‡∏Å AI ‡∏ä‡∏ô‡∏∞
                        print("üß† AI ‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏Å‡∏°‡∏ô‡∏µ‡πâ (Q-values ‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°)")
                    else:
                        print("üß† AI ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏°‡πÄ‡∏™‡∏°‡∏≠‡∏ô‡∏µ‡πâ")
                else:
                    print("üìù AI ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏°‡∏ô‡∏µ‡πâ (‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢)")

                break

            game.current_player *= -1

        if winner is not None and input("\n‡πÄ‡∏•‡πà‡∏ô‡∏≠‡∏µ‡∏Å‡πÑ‡∏´‡∏°? (y/n): ").lower() == 'n':
            break

    ai.save_q_table()
    print("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡πâ‡∏ß!")


def main():
    print("üéÆ === Q-Learning Tic-Tac-Toe AI ===")
    print("AI ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î")

    json_file = 'game_stats.json'
    if not os.path.exists(json_file):
        initial_data = {
            "all_game": 0,
            "win": 0,
            "lose": 0,
            "draw": 0
        }
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(initial_data, f, indent=4, ensure_ascii=False)
        print(f"Created initial file '{json_file}' with default data.")
    game_data = load_json_data(json_file)

    ai = TicTacToeQLearning()

    if not os.path.exists(ai.data_file) or len(ai.q_table) == 0:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô AI ‡πÉ‡∏´‡∏°‡πà...")
        train_ai(ai, game_data, 1000)
    else:
        stats = ai.get_learning_stats()
        print(f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß ({stats['total_states']} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå)")
        print("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏•‡πà‡∏ô!")

    play_with_human(ai, game_data)

    if update_json_file(json_file, game_data):
        print("Updated game data:", game_data)


if __name__ == "__main__":
    main()